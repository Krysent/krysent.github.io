    背景：上传比较大的文件时（几个G），遇到网络中断或页面关闭，之前上传的内容就都没了，就会遇到下次又需要重新上传，不符合用户体验。

    改善：当用户上传文件过大时，需要进行大文件上传处理。将大文件分成一个个的小份文件，然后单个上传，把小文件上传到服务器，由服务器再组装。做断点续传、断开重传、切片上传。

    方案：

- 前端切片，每一片chunk（比如1024）

- 将切片传递给后端，要给每一份切片进行取名，使用hash，index

- 后端切片组合

附加：

- 前端切片，当前端切片和取名的时候会卡顿，使用web worker开辟新的线程进行后台运算，处理完交给主线程进行上传

- 切完后将blob存储到本地indexDb里，下次用户进入上传环节后，可以先在本地嗅探一下未上传完的切片，继续上传



## 前端如何将大文件进行分片处理？
![](https://cdn.nlark.com/yuque/0/2025/png/29756964/1740794648384-fef68542-a943-4cbb-9852-f825bfa40b88.png)



### 1、对File对象进行切片 slice ，得到一个个 Blob类型的文件
![](https://cdn.nlark.com/yuque/0/2025/png/29756964/1740831127741-041558c2-27e3-49a3-8bbc-179d3a609899.png)

![](https://cdn.nlark.com/yuque/0/2025/png/29756964/1740831948633-53910e40-614e-46bd-960f-4835a5ab987b.png)

使用Blob对象内置的slice方法进行切片

![](https://cdn.nlark.com/yuque/0/2025/png/29756964/1740833887312-c6c8c15d-7cd0-4e4c-ab44-06ebc3abafd1.png)

创建createFileChunks函数，将file流给进去，chunkSize为每一份的文件大小（单位是字节），输出切好的每一份文件result。File文件流或者Blob只是保存了文件的基本信息（如名字、大小、地址信息等），并不是文件本身，所以切片的时候不会很慢

![](https://cdn.nlark.com/yuque/0/2025/png/29756964/1740832029869-5489c2e8-7937-4ce2-a173-c5f2a767c849.png)



File 对象:它表示一组文件，我们使用`<input type="file">`选择文件时，这些文件被存储在 File 对象中。

Blob对象:Blob对象表示二进制数据，常用来表示大型数据对象(如图片音频等)。File对象是Blob对象的一个子类，它继承了Blob对象的所有属性和方法。

formData对象:前端先将文件存储在formData对象中，才能传给后端。



### 2、将切好的一个个chunks逐一上传
![画板](https://cdn.nlark.com/yuque/0/2025/jpeg/29756964/1740832480228-68793f5c-24f3-4683-a37a-ad2d9746c38e.jpeg)

**上传的时候，将分片进行逐一上传，如果上传过程中中断了（如网络中断、页面关闭等），之前上传过的分片就不用再上传了，则接着从上次传递完的那个分片开始继续上传，这个叫做切片的文件秒传**

****

**原理：**

![](https://cdn.nlark.com/yuque/0/2025/png/29756964/1740832839485-266faa4d-916e-4673-ae29-73dc85372d12.png)

重新上传的时，询问服务器之前上传的阶段是在哪里？上传了哪些编号的分片，还需要上传哪些分片，具体已经上传完成的是哪些切片，还要从第几个开始继续上传？ 服务器需要告知这些信息。

此时需要用一个代表文件分片的Id，可以使用hash值来标识每一份切片。

使用hash来标记，hash是一种算法，可以把任何数据来换算成标记的字符串，（不可逆，只能将数据记录成一段字符串），利用hash值来代表文件切片的整个数据，进行id的记录。因此服务端可以使用切片的hash值来记录当前文件有没有上传过。

**常见的hash算法有**  **md5 ，推荐库为【spark-md5】**





